{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tweetnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install symspellpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import string\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from scipy.special import softmax\n",
    "\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "import contractions\n",
    "\n",
    "\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Krithika\n",
      "[nltk_data]     JK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krithika JK\\AppData\\Local\\Temp\\ipykernel_23628\\908094907.py:1: DtypeWarning: Columns (6,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('replyTweets.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('replyTweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 171006 entries, 0 to 171005\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   id               171006 non-null  int64  \n",
      " 1   createdAt        171006 non-null  object \n",
      " 2   fullName         170988 non-null  object \n",
      " 3   userName         171006 non-null  object \n",
      " 4   profileImage     171006 non-null  object \n",
      " 5   fullText         171006 non-null  object \n",
      " 6   replyTo          154370 non-null  object \n",
      " 7   lang             171006 non-null  object \n",
      " 8   quoteCount       171006 non-null  int64  \n",
      " 9   retweetCount     171006 non-null  object \n",
      " 10  replyCount       171006 non-null  int64  \n",
      " 11  likeCount        171006 non-null  int64  \n",
      " 12  viewCount        120511 non-null  float64\n",
      " 13  sentimentLabel1  995 non-null     float64\n",
      " 14  sentimentLabel2  250 non-null     float64\n",
      "dtypes: float64(3), int64(4), object(8)\n",
      "memory usage: 19.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>fullName</th>\n",
       "      <th>userName</th>\n",
       "      <th>profileImage</th>\n",
       "      <th>fullText</th>\n",
       "      <th>replyTo</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>sentimentLabel1</th>\n",
       "      <th>sentimentLabel2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1773239429001355747</td>\n",
       "      <td>2024-03-28 06:43:19+00:00</td>\n",
       "      <td>Stella Patchouli</td>\n",
       "      <td>StellaPatch</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/175397939...</td>\n",
       "      <td>@nytimes The curse on Musk iis working!\\r\\nüî•‚òîüê±üê±ü§πüí•</td>\n",
       "      <td>1772931578835939584.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1773173585424548296</td>\n",
       "      <td>2024-03-28 02:21:41+00:00</td>\n",
       "      <td>Ceti Alpha V</td>\n",
       "      <td>RichGreenwood5</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/122737855...</td>\n",
       "      <td>@elonmusk and @joebiden walk into a Chinese ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1772931578835939531</td>\n",
       "      <td>2024-03-27 10:20:02+00:00</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/109824457...</td>\n",
       "      <td>Elon Musk helped create China‚Äôs electric vehic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>98</td>\n",
       "      <td>113250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                  createdAt            fullName  \\\n",
       "0  1773239429001355747  2024-03-28 06:43:19+00:00    Stella Patchouli   \n",
       "1  1773173585424548296  2024-03-28 02:21:41+00:00        Ceti Alpha V   \n",
       "2  1772931578835939531  2024-03-27 10:20:02+00:00  The New York Times   \n",
       "\n",
       "         userName                                       profileImage  \\\n",
       "0     StellaPatch  https://pbs.twimg.com/profile_images/175397939...   \n",
       "1  RichGreenwood5  https://pbs.twimg.com/profile_images/122737855...   \n",
       "2         nytimes  https://pbs.twimg.com/profile_images/109824457...   \n",
       "\n",
       "                                            fullText                replyTo  \\\n",
       "0  @nytimes The curse on Musk iis working!\\r\\nüî•‚òîüê±üê±ü§πüí•  1772931578835939584.0   \n",
       "1  @elonmusk and @joebiden walk into a Chinese ba...                    NaN   \n",
       "2  Elon Musk helped create China‚Äôs electric vehic...                    NaN   \n",
       "\n",
       "  lang  quoteCount retweetCount  replyCount  likeCount  viewCount  \\\n",
       "0   en           0            0           0          0        9.0   \n",
       "1   en           0            0           0          0       10.0   \n",
       "2   en           5           20          52         98   113250.0   \n",
       "\n",
       "   sentimentLabel1  sentimentLabel2  \n",
       "0              0.0              1.0  \n",
       "1              2.0              0.0  \n",
       "2              1.0              1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171006, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en                                                    169915\n",
       "tl                                                       316\n",
       "ht                                                       261\n",
       "fr                                                       133\n",
       "es                                                       100\n",
       "in                                                        37\n",
       "nl                                                        28\n",
       "no                                                        25\n",
       "de                                                        24\n",
       "sv                                                        24\n",
       "it                                                        23\n",
       "et                                                        21\n",
       "pt                                                        18\n",
       "tr                                                        16\n",
       "zxx                                                       13\n",
       "qme                                                       12\n",
       "und                                                        7\n",
       "da                                                         6\n",
       "ca                                                         5\n",
       "lv                                                         3\n",
       "cy                                                         3\n",
       "ar                                                         3\n",
       "pl                                                         3\n",
       "hi                                                         2\n",
       "eu                                                         1\n",
       "is                                                         1\n",
       "vi                                                         1\n",
       "hu                                                         1\n",
       "qam                                                        1\n",
       "qht                                                        1\n",
       "lt                                                         1\n",
       "@nytimes 1.1 million likes https://t.co/cv46nm6gQD         1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only eng tweets\n",
    "data = data[data['lang']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    169915\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_tweet'] = data.fullText.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         @nytimes the curse on musk iis working!\\r\\nüî•‚òîüê±üê±ü§πüí•\n",
       "1         @elonmusk and @joebiden walk into a chinese ba...\n",
       "2         elon musk helped create china‚Äôs electric vehic...\n",
       "3         lies.\\r\\n\\r\\nmusk faced even greater challenge...\n",
       "4         @sp4rksaflyin @nytimes these electric tesla ca...\n",
       "                                ...                        \n",
       "171001    @wsj what‚Äôs more democratic than a referendum ...\n",
       "171002    @wsj is he inhuman? why he has no right to ope...\n",
       "171003    @wsj it's hilarious watching elon play you guy...\n",
       "171004                                          @wsj uh so?\n",
       "171005    @wsj no, trump is old news! he has to many law...\n",
       "Name: cleaned_tweet, Length: 169915, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace https\n",
    "data.cleaned_tweet = data.cleaned_tweet.apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\n",
    "data.cleaned_tweet.apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cleaned_tweet = data.cleaned_tweet.apply(lambda x: re.sub(r'{link}', '', x))\n",
    "data.cleaned_tweet = data.cleaned_tweet.apply(lambda x: re.sub(r\"\\[video\\]\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to replace '@username' with '@user' except for '@elonmusk'\n",
    "# def replace_username(text):\n",
    "#     # Replace all occurrences of '@username' except '@elonmusk'\n",
    "#     return re.sub(r'(@\\w+)(?!elonmusk)', r'@user', text)\n",
    "\n",
    "# # Apply the function to the 'tweet_text' column\n",
    "# data['cleaned_tweet'] = data['cleaned_tweet'].apply(replace_username)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(text):\n",
    "    return re.sub(r'@\\w+', '', text)\n",
    "data['cleaned_tweet'] = data['cleaned_tweet'].apply(remove_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "0         @nytimes The curse on Musk iis working!\\r\\nüî•‚òîüê±üê±ü§πüí•\n",
      "1         @elonmusk and @joebiden walk into a Chinese ba...\n",
      "2         Elon Musk helped create China‚Äôs electric vehic...\n",
      "3         Lies.\\r\\n\\r\\nMusk faced even greater challenge...\n",
      "4         @Sp4rksaflyin @nytimes These Electric Tesla ca...\n",
      "                                ...                        \n",
      "171001    @WSJ What‚Äôs more democratic than a referendum ...\n",
      "171002    @WSJ Is he inhuman? Why he has no right to ope...\n",
      "171003    @WSJ It's hilarious watching Elon play you guy...\n",
      "171004                                          @WSJ Uh so?\n",
      "171005    @WSJ No, Trump is old news! He has to many law...\n",
      "Name: fullText, Length: 169915, dtype: object\n",
      "\n",
      "Expanded Text:\n",
      "0                     the curse on musk iis working! üî•‚òîüê±üê±ü§πüí•\n",
      "1         and walk into a chinese bar. elon makes money ...\n",
      "2         elon musk helped create china‚Äôs electric vehic...\n",
      "3         lies. musk faced even greater challenges from ...\n",
      "4         these electric tesla cars cannot start in the ...\n",
      "                                ...                        \n",
      "171001    what is more democratic than a referendum on t...\n",
      "171002    is he inhuman? why he has no right to open a b...\n",
      "171003    it is hilarious watching elon play you guys li...\n",
      "171004                                               uh so?\n",
      "171005    no, trump is old news! he has to many lawsuits...\n",
      "Name: cleaned_tweet, Length: 169915, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Add LOL definition to contractions\n",
    "\n",
    "import contractions\n",
    "\n",
    "# Function to expand contractions\n",
    "def expand_contractions(text):\n",
    "    expanded_words = []\n",
    "    for word in text.split():\n",
    "        expanded_words.append(contractions.fix(word))\n",
    "    return ' '.join(expanded_words)\n",
    "\n",
    "# Apply the function to the 'fullText' column\n",
    "data['cleaned_tweet'] = data['cleaned_tweet'].apply(expand_contractions)\n",
    "\n",
    "# Display the original and expanded texts\n",
    "print(\"Original Text:\")\n",
    "print(data['fullText'])\n",
    "print(\"\\nExpanded Text:\")\n",
    "print(data['cleaned_tweet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with emojis: I'm feeling üòä today!\n",
      "Text without emojis: I'm feeling :smiling_face_with_smiling_eyes: today!\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "def convert_emojis_to_text(text):\n",
    "    # Convert emojis to text\n",
    "    text_with_emojis = emoji.demojize(text)\n",
    "    return text_with_emojis\n",
    "\n",
    "# Example usage\n",
    "text_with_emojis = \"I'm feeling üòä today!\"\n",
    "text_without_emojis = convert_emojis_to_text(text_with_emojis)\n",
    "\n",
    "# Apply to data\n",
    "data['cleaned_tweet'] = data['cleaned_tweet'].apply(convert_emojis_to_text)\n",
    "\n",
    "print(\"Text with emojis:\", text_with_emojis)\n",
    "print(\"Text without emojis:\", text_without_emojis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #remove stop words \n",
    "\n",
    "# # from nltk.corpus import stopwords\n",
    "# # nltk.download('stopwords')\n",
    "# # nltk.download('punkt')\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     word_tokens = nltk.word_tokenize(text)\n",
    "#     filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "#     return ' '.join(filtered_text)\n",
    "\n",
    "# # Apply the remove_stopwords function to the 'cleaned_tweet' column\n",
    "# data['cleaned_tweet'] = data['cleaned_tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spell check - does not work. It takes too long to run\n",
    "# sypmspellpy does not work\n",
    "# def spell_check(tweet):\n",
    "#     spell = SpellChecker()\n",
    "#     corrected_tokens = []\n",
    "#     tokens = tweet.split()  # Assuming each tweet is tokenized already\n",
    "#     for token in tokens:\n",
    "#         # Check if the token is misspelled\n",
    "#         corrected_token = spell.correction(token)\n",
    "#         if corrected_token is not None:\n",
    "#             corrected_tokens.append(corrected_token)\n",
    "#     return ' '.join(corrected_tokens)\n",
    "\n",
    "# data['cleaned_tweet'] = data['cleaned_tweet'].apply(spell_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non letter\n",
    "data.cleaned_tweet = data.cleaned_tweet.apply(lambda x: re.sub(r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tknzr = TweetTokenizer()\n",
    "# data['tokens'] = data['cleaned_tweet'].apply(tknzr.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "w_tokenizer = TweetTokenizer()\n",
    "def lemmatize_text(text):\n",
    "    return [(lemmatizer.lemmatize(w)) for w in \\\n",
    "                                     w_tokenizer.tokenize((text))]\n",
    "data['tokens'] = data['cleaned_tweet'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCUATION_LIST = list(string.punctuation)\n",
    "def remove_punctuation(word_list):\n",
    "    \"\"\"Remove punctuation tokens from a list of tokens\"\"\"\n",
    "    return [w for w in word_list if w not in PUNCUATION_LIST]\n",
    "data['tokens'] = data['tokens'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['cleaned_tweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullText</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@nytimes The curse on Musk iis working!\\r\\nüî•‚òîüê±üê±ü§πüí•</td>\n",
       "      <td>the curse on musk iis working :fire::umbrellaw...</td>\n",
       "      <td>[the, curse, on, musk, ii, working, fire, ::, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@elonmusk and @joebiden walk into a Chinese ba...</td>\n",
       "      <td>and walk into a chinese bar elon makes money l...</td>\n",
       "      <td>[and, walk, into, a, chinese, bar, elon, make,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elon Musk helped create China‚Äôs electric vehic...</td>\n",
       "      <td>elon musk helped create chinas electric vehicl...</td>\n",
       "      <td>[elon, musk, helped, create, china, electric, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lies.\\r\\n\\r\\nMusk faced even greater challenge...</td>\n",
       "      <td>lies musk faced even greater challenges from h...</td>\n",
       "      <td>[lie, musk, faced, even, greater, challenge, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Sp4rksaflyin @nytimes These Electric Tesla ca...</td>\n",
       "      <td>these electric tesla cars cannot start in the ...</td>\n",
       "      <td>[these, electric, tesla, car, cannot, start, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>@global13news @guardiannews It‚Äôs a pretty repu...</td>\n",
       "      <td>it is a pretty reputable source sensor tower e...</td>\n",
       "      <td>[it, is, a, pretty, reputable, source, sensor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>@guardiannews Haha... Off course it has üòã\\r\\nA...</td>\n",
       "      <td>haha off course it has :facesavoringfood: and ...</td>\n",
       "      <td>[haha, off, course, it, ha, facesavoringfood, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Please share this post with your friends who s...</td>\n",
       "      <td>please share this post with your friends who s...</td>\n",
       "      <td>[please, share, this, post, with, your, friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@guardiannews No. This is erroneous.</td>\n",
       "      <td>no this is erroneous</td>\n",
       "      <td>[no, this, is, erroneous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@Lukestonehm @pascarey90 @guardiannews @elonmu...</td>\n",
       "      <td>data is from sensor tower who musk has quoted ...</td>\n",
       "      <td>[data, is, from, sensor, tower, who, musk, ha,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             fullText  \\\n",
       "0   @nytimes The curse on Musk iis working!\\r\\nüî•‚òîüê±üê±ü§πüí•   \n",
       "1   @elonmusk and @joebiden walk into a Chinese ba...   \n",
       "2   Elon Musk helped create China‚Äôs electric vehic...   \n",
       "3   Lies.\\r\\n\\r\\nMusk faced even greater challenge...   \n",
       "4   @Sp4rksaflyin @nytimes These Electric Tesla ca...   \n",
       "..                                                ...   \n",
       "95  @global13news @guardiannews It‚Äôs a pretty repu...   \n",
       "96  @guardiannews Haha... Off course it has üòã\\r\\nA...   \n",
       "97  Please share this post with your friends who s...   \n",
       "98               @guardiannews No. This is erroneous.   \n",
       "99  @Lukestonehm @pascarey90 @guardiannews @elonmu...   \n",
       "\n",
       "                                        cleaned_tweet  \\\n",
       "0   the curse on musk iis working :fire::umbrellaw...   \n",
       "1   and walk into a chinese bar elon makes money l...   \n",
       "2   elon musk helped create chinas electric vehicl...   \n",
       "3   lies musk faced even greater challenges from h...   \n",
       "4   these electric tesla cars cannot start in the ...   \n",
       "..                                                ...   \n",
       "95  it is a pretty reputable source sensor tower e...   \n",
       "96  haha off course it has :facesavoringfood: and ...   \n",
       "97  please share this post with your friends who s...   \n",
       "98                               no this is erroneous   \n",
       "99  data is from sensor tower who musk has quoted ...   \n",
       "\n",
       "                                               tokens  \n",
       "0   [the, curse, on, musk, ii, working, fire, ::, ...  \n",
       "1   [and, walk, into, a, chinese, bar, elon, make,...  \n",
       "2   [elon, musk, helped, create, china, electric, ...  \n",
       "3   [lie, musk, faced, even, greater, challenge, f...  \n",
       "4   [these, electric, tesla, car, cannot, start, i...  \n",
       "..                                                ...  \n",
       "95  [it, is, a, pretty, reputable, source, sensor,...  \n",
       "96  [haha, off, course, it, ha, facesavoringfood, ...  \n",
       "97  [please, share, this, post, with, your, friend...  \n",
       "98                          [no, this, is, erroneous]  \n",
       "99  [data, is, from, sensor, tower, who, musk, ha,...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['fullText', 'cleaned_tweet', 'tokens']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Convert list of token lists to a single list of tokens\n",
    "# all_tokens = [token for tokens_list in data['tokens'] for token in tokens_list]\n",
    "\n",
    "# # Create a WordCloud object with a TrueType font specified\n",
    "# wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(nltk.FreqDist(all_tokens)))\n",
    "\n",
    "# # Plot the word cloud\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.imshow(wordcloud, interpolation='bilinear')\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 169915 entries, 0 to 171005\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   id               169915 non-null  int64  \n",
      " 1   createdAt        169915 non-null  object \n",
      " 2   fullName         169897 non-null  object \n",
      " 3   userName         169915 non-null  object \n",
      " 4   profileImage     169915 non-null  object \n",
      " 5   fullText         169915 non-null  object \n",
      " 6   replyTo          153427 non-null  object \n",
      " 7   lang             169915 non-null  object \n",
      " 8   quoteCount       169915 non-null  int64  \n",
      " 9   retweetCount     169915 non-null  object \n",
      " 10  replyCount       169915 non-null  int64  \n",
      " 11  likeCount        169915 non-null  int64  \n",
      " 12  viewCount        119700 non-null  float64\n",
      " 13  sentimentLabel1  995 non-null     float64\n",
      " 14  sentimentLabel2  250 non-null     float64\n",
      " 15  cleaned_tweet    169915 non-null  object \n",
      " 16  tokens           169915 non-null  object \n",
      "dtypes: float64(3), int64(4), object(10)\n",
      "memory usage: 23.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('preprocesssed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBerta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    566\n",
       "0.0    294\n",
       "2.0    135\n",
       "Name: sentimentLabel1, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data['sentimentLabel1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 995 entries, 0 to 998\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               995 non-null    int64  \n",
      " 1   createdAt        995 non-null    object \n",
      " 2   fullName         995 non-null    object \n",
      " 3   userName         995 non-null    object \n",
      " 4   profileImage     995 non-null    object \n",
      " 5   fullText         995 non-null    object \n",
      " 6   replyTo          794 non-null    object \n",
      " 7   lang             995 non-null    object \n",
      " 8   quoteCount       995 non-null    int64  \n",
      " 9   retweetCount     995 non-null    object \n",
      " 10  replyCount       995 non-null    int64  \n",
      " 11  likeCount        995 non-null    int64  \n",
      " 12  viewCount        995 non-null    float64\n",
      " 13  sentimentLabel1  995 non-null    float64\n",
      " 14  sentimentLabel2  250 non-null    float64\n",
      " 15  cleaned_tweet    995 non-null    object \n",
      " 16  tokens           995 non-null    object \n",
      "dtypes: float64(3), int64(4), object(10)\n",
      "memory usage: 139.9+ KB\n"
     ]
    }
   ],
   "source": [
    "labeled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krithika JK\\AppData\\Local\\Temp\\ipykernel_7796\\3995215218.py:27: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  train_labels = torch.tensor(list(train_data['sentimentLabel1']), dtype=torch.long)\n",
      "C:\\Users\\Krithika JK\\AppData\\Local\\Temp\\ipykernel_7796\\3995215218.py:28: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  val_labels = torch.tensor(list(val_data['sentimentLabel1']), dtype=torch.long)\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\Krithika JK\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [18:26<00:00, 44.26s/batches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.814280799627304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [29:10<00:00, 70.02s/batches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6303270065784454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [11:27<00:00, 27.50s/batches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.43103381991386414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:51<00:00,  7.31s/batches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.55      0.89      0.68        54\n",
      "    Negative       0.88      0.69      0.78       120\n",
      "     Neutral       0.88      0.60      0.71        25\n",
      "\n",
      "    accuracy                           0.73       199\n",
      "   macro avg       0.77      0.73      0.72       199\n",
      "weighted avg       0.79      0.73      0.74       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Load your datasets\n",
    "# Assuming your datasets are 'data' and 'labeled_data' DataFrames\n",
    "\n",
    "# Split labeled data into train and validation sets\n",
    "train_data, val_data = train_test_split(labeled_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load pre-trained RoBERTa tokenizer\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "# Tokenize text data\n",
    "train_encodings = tokenizer(list(train_data['cleaned_tweet']), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "val_encodings = tokenizer(list(val_data['cleaned_tweet']), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "# Convert labels to tensors of type torch.long\n",
    "train_labels = torch.tensor(list(train_data['sentimentLabel1']), dtype=torch.long)\n",
    "val_labels = torch.tensor(list(val_data['sentimentLabel1']), dtype=torch.long)\n",
    "\n",
    "# Define TensorDatasets for training and validation\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], val_labels)\n",
    "\n",
    "# Initialize the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL, config=config)\n",
    "\n",
    "# Define training parameters\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Prepare DataLoader for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=RandomSampler(train_dataset))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=SequentialSampler(val_dataset))\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', unit='batches'):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "        loss = loss_fn(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval() \n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc='Evaluation', unit='batches'):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=['Positive', 'Negative', 'Neutral'])\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>roberta_predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>so you are reduced to these type political hit...</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>basically and teamed up drop your subscriptions</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>don lemon joins erin exclusively to talk about...</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>what a joke of an organization you are cnn you...</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>nobody cares</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  predicted_sentiment  \\\n",
       "924  so you are reduced to these type political hit...                    0   \n",
       "525    basically and teamed up drop your subscriptions                    1   \n",
       "568  don lemon joins erin exclusively to talk about...                    1   \n",
       "658  what a joke of an organization you are cnn you...                    0   \n",
       "634                                       nobody cares                    0   \n",
       "\n",
       "    roberta_predicted_sentiment  \n",
       "924                    Positive  \n",
       "525                    Negative  \n",
       "568                    Negative  \n",
       "658                    Positive  \n",
       "634                    Positive  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with predicted labels and corresponding text\n",
    "df_predicted = pd.DataFrame({'text': val_data['cleaned_tweet'], 'predicted_sentiment': all_preds})\n",
    "df_predicted['roberta_predicted_sentiment'] = df_predicted['predicted_sentiment'].map({0: 'Positive', 1: 'Negative', 2: 'Neutral'})\n",
    "\n",
    "df_predicted.head(5)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df_predicted.to_csv(\"predicted_labels_with_text.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, df_predicted['predicted_sentiment']], axis=1)\n",
    "data = pd.concat([data, df_predicted['roberta_predicted_sentiment']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>fullName</th>\n",
       "      <th>userName</th>\n",
       "      <th>profileImage</th>\n",
       "      <th>fullText</th>\n",
       "      <th>replyTo</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>sentimentLabel1</th>\n",
       "      <th>sentimentLabel2</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>tokens</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>roberta_predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1772945117516571098</td>\n",
       "      <td>2024-03-27 11:13:50+00:00</td>\n",
       "      <td>Ahmed</td>\n",
       "      <td>Ahmedali7104</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/173922670...</td>\n",
       "      <td>@nytimes Updates</td>\n",
       "      <td>1772931578835939584.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>updates</td>\n",
       "      <td>[update]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1772932914474360899</td>\n",
       "      <td>2024-03-27 10:25:20+00:00</td>\n",
       "      <td>Dog Fanatic</td>\n",
       "      <td>DogFanatic101</td>\n",
       "      <td>https://abs.twimg.com/sticky/default_profile_i...</td>\n",
       "      <td>@nytimes Wait. I thought that was Elaine from ...</td>\n",
       "      <td>1772931578835939584.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wait i thought that was elaine from seinfeld</td>\n",
       "      <td>[wait, i, thought, that, wa, elaine, from, sei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1772932728616255540</td>\n",
       "      <td>2024-03-27 10:24:36+00:00</td>\n",
       "      <td>Julio the guard donkey ‚úåüèΩ üá∫üá∏üåª</td>\n",
       "      <td>DonkeyJulio</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/154292508...</td>\n",
       "      <td>@nytimes Elon Musk is one of those people who ...</td>\n",
       "      <td>1772931578835939584.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>elon musk is one of those people who does not ...</td>\n",
       "      <td>[elon, musk, is, one, of, those, people, who, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1772931981317226740</td>\n",
       "      <td>2024-03-27 10:21:38+00:00</td>\n",
       "      <td>Lisa Robertson</td>\n",
       "      <td>sugarbritches09</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/172317735...</td>\n",
       "      <td>@nytimes You guys hate him because he isn't pa...</td>\n",
       "      <td>1772931578835939584.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>you guys hate him because he is not part of yo...</td>\n",
       "      <td>[you, guy, hate, him, because, he, is, not, pa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1772931788295352750</td>\n",
       "      <td>2024-03-27 10:20:52+00:00</td>\n",
       "      <td>Fatima Khan</td>\n",
       "      <td>FatimaKhan47025</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/175655059...</td>\n",
       "      <td>@nytimes Hope! The problems will be tackled</td>\n",
       "      <td>1772931578835939584.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>hope the problems will be tackled</td>\n",
       "      <td>[hope, the, problem, will, be, tackled]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1772886510364230026</td>\n",
       "      <td>2024-03-27 07:20:57+00:00</td>\n",
       "      <td>Usagi</td>\n",
       "      <td>Beehave99</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/174571711...</td>\n",
       "      <td>It also means that vehicles built there are a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>it also means that vehicles built there are a ...</td>\n",
       "      <td>[it, also, mean, that, vehicle, built, there, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1772884337937064142</td>\n",
       "      <td>2024-03-27 07:12:19+00:00</td>\n",
       "      <td>Dumb Alpha</td>\n",
       "      <td>dumbalpha_</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/160610895...</td>\n",
       "      <td>@nytimes Elon bitching about the NYT in 3,2,1‚Ä¶</td>\n",
       "      <td>1772883760859496960.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>elon bitching about the nyt in</td>\n",
       "      <td>[elon, bitching, about, the, nyt, in]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1773004981504708673</td>\n",
       "      <td>2024-03-27 15:11:43+00:00</td>\n",
       "      <td>Gleb Bahmutov</td>\n",
       "      <td>bahmutov</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/117450474...</td>\n",
       "      <td>@hackettholistic @guardiannews Blue check. Block</td>\n",
       "      <td>1772760403652587520.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>blue check block</td>\n",
       "      <td>[blue, check, block]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1772965291372286204</td>\n",
       "      <td>2024-03-27 12:34:00+00:00</td>\n",
       "      <td>Luis A. Vegas Vicentini</td>\n",
       "      <td>lavvspan</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/177113009...</td>\n",
       "      <td>@guardiannews @nickhedley I actually like the ...</td>\n",
       "      <td>1772682700656349696.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>i actually like the platform much better than ...</td>\n",
       "      <td>[i, actually, like, the, platform, much, bette...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1772959302291968195</td>\n",
       "      <td>2024-03-27 12:10:12+00:00</td>\n",
       "      <td>Scott</td>\n",
       "      <td>minimeadow</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/122055987...</td>\n",
       "      <td>@GenePavlova @guardiannews There are more fake...</td>\n",
       "      <td>1772717872898609664.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>there are more fake accounts than ever</td>\n",
       "      <td>[there, are, more, fake, account, than, ever]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                  createdAt  \\\n",
       "10  1772945117516571098  2024-03-27 11:13:50+00:00   \n",
       "23  1772932914474360899  2024-03-27 10:25:20+00:00   \n",
       "25  1772932728616255540  2024-03-27 10:24:36+00:00   \n",
       "29  1772931981317226740  2024-03-27 10:21:38+00:00   \n",
       "30  1772931788295352750  2024-03-27 10:20:52+00:00   \n",
       "39  1772886510364230026  2024-03-27 07:20:57+00:00   \n",
       "44  1772884337937064142  2024-03-27 07:12:19+00:00   \n",
       "55  1773004981504708673  2024-03-27 15:11:43+00:00   \n",
       "59  1772965291372286204  2024-03-27 12:34:00+00:00   \n",
       "60  1772959302291968195  2024-03-27 12:10:12+00:00   \n",
       "\n",
       "                         fullName         userName  \\\n",
       "10                          Ahmed     Ahmedali7104   \n",
       "23                    Dog Fanatic    DogFanatic101   \n",
       "25  Julio the guard donkey ‚úåüèΩ üá∫üá∏üåª      DonkeyJulio   \n",
       "29                 Lisa Robertson  sugarbritches09   \n",
       "30                    Fatima Khan  FatimaKhan47025   \n",
       "39                          Usagi        Beehave99   \n",
       "44                     Dumb Alpha       dumbalpha_   \n",
       "55                  Gleb Bahmutov         bahmutov   \n",
       "59        Luis A. Vegas Vicentini         lavvspan   \n",
       "60                          Scott       minimeadow   \n",
       "\n",
       "                                         profileImage  \\\n",
       "10  https://pbs.twimg.com/profile_images/173922670...   \n",
       "23  https://abs.twimg.com/sticky/default_profile_i...   \n",
       "25  https://pbs.twimg.com/profile_images/154292508...   \n",
       "29  https://pbs.twimg.com/profile_images/172317735...   \n",
       "30  https://pbs.twimg.com/profile_images/175655059...   \n",
       "39  https://pbs.twimg.com/profile_images/174571711...   \n",
       "44  https://pbs.twimg.com/profile_images/160610895...   \n",
       "55  https://pbs.twimg.com/profile_images/117450474...   \n",
       "59  https://pbs.twimg.com/profile_images/177113009...   \n",
       "60  https://pbs.twimg.com/profile_images/122055987...   \n",
       "\n",
       "                                             fullText                replyTo  \\\n",
       "10                                   @nytimes Updates  1772931578835939584.0   \n",
       "23  @nytimes Wait. I thought that was Elaine from ...  1772931578835939584.0   \n",
       "25  @nytimes Elon Musk is one of those people who ...  1772931578835939584.0   \n",
       "29  @nytimes You guys hate him because he isn't pa...  1772931578835939584.0   \n",
       "30        @nytimes Hope! The problems will be tackled  1772931578835939584.0   \n",
       "39  It also means that vehicles built there are a ...                    NaN   \n",
       "44     @nytimes Elon bitching about the NYT in 3,2,1‚Ä¶  1772883760859496960.0   \n",
       "55   @hackettholistic @guardiannews Blue check. Block  1772760403652587520.0   \n",
       "59  @guardiannews @nickhedley I actually like the ...  1772682700656349696.0   \n",
       "60  @GenePavlova @guardiannews There are more fake...  1772717872898609664.0   \n",
       "\n",
       "   lang  quoteCount retweetCount  replyCount  likeCount  viewCount  \\\n",
       "10   en           0            0           0          0      270.0   \n",
       "23   en           0            0           0          2      210.0   \n",
       "25   en           0            0           1          2       29.0   \n",
       "29   en           0            0           0          3       10.0   \n",
       "30   en           0            0           0          5      144.0   \n",
       "39   en           0            0           0          0       50.0   \n",
       "44   en           0            0           0          3       16.0   \n",
       "55   en           0            0           0          0        3.0   \n",
       "59   en           0            0           1          1       25.0   \n",
       "60   en           0            0           0          0        6.0   \n",
       "\n",
       "    sentimentLabel1  sentimentLabel2  \\\n",
       "10              1.0              1.0   \n",
       "23              1.0              1.0   \n",
       "25              0.0              0.0   \n",
       "29              2.0              2.0   \n",
       "30              2.0              2.0   \n",
       "39              0.0              0.0   \n",
       "44              0.0              0.0   \n",
       "55              0.0              0.0   \n",
       "59              2.0              2.0   \n",
       "60              0.0              0.0   \n",
       "\n",
       "                                        cleaned_tweet  \\\n",
       "10                                            updates   \n",
       "23       wait i thought that was elaine from seinfeld   \n",
       "25  elon musk is one of those people who does not ...   \n",
       "29  you guys hate him because he is not part of yo...   \n",
       "30                  hope the problems will be tackled   \n",
       "39  it also means that vehicles built there are a ...   \n",
       "44                    elon bitching about the nyt in    \n",
       "55                                   blue check block   \n",
       "59  i actually like the platform much better than ...   \n",
       "60             there are more fake accounts than ever   \n",
       "\n",
       "                                               tokens  predicted_sentiment  \\\n",
       "10                                           [update]                  1.0   \n",
       "23  [wait, i, thought, that, wa, elaine, from, sei...                  1.0   \n",
       "25  [elon, musk, is, one, of, those, people, who, ...                  0.0   \n",
       "29  [you, guy, hate, him, because, he, is, not, pa...                  0.0   \n",
       "30            [hope, the, problem, will, be, tackled]                  1.0   \n",
       "39  [it, also, mean, that, vehicle, built, there, ...                  0.0   \n",
       "44              [elon, bitching, about, the, nyt, in]                  0.0   \n",
       "55                               [blue, check, block]                  0.0   \n",
       "59  [i, actually, like, the, platform, much, bette...                  2.0   \n",
       "60      [there, are, more, fake, account, than, ever]                  1.0   \n",
       "\n",
       "   roberta_predicted_sentiment  \n",
       "10                    Negative  \n",
       "23                    Negative  \n",
       "25                    Positive  \n",
       "29                    Positive  \n",
       "30                    Negative  \n",
       "39                    Positive  \n",
       "44                    Positive  \n",
       "55                    Positive  \n",
       "59                     Neutral  \n",
       "60                    Negative  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['roberta_predicted_sentiment'].notnull()].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the labels\n",
    "labels_definition = config.id2label\n",
    "print(\"Labels Definition:\", labels_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
